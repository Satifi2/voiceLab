model_name = "transformer_ctc_big"
mfcc_feature = 128
max_sentence_len = 30
max_mfcc_seqlen = 460
num_attention_heads = 8
num_layers = 12
ffn_hidden_dim = 4096
vocab_size = 4336
device = 'cuda'
learning_rate = 0.00001
dataloader_batch_size = 64