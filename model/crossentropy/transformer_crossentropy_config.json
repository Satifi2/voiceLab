{
    "model_name": "transformer_crossentropy",
    "sampling_rate": 8000,
    "hop_length": 640,
    "mfcc_feature": 128,
    "d_model": 128,
    "num_attention_heads": 8,
    "num_layers": 16,
    "ffn_hidden_dim": 4096,
    "vocab_size": 4337,
    "device": "cuda",
    "learning_rate": 5e-05,
    "dataloader_batch_size": 64,
    "dropout": 0.1,
    "blank_token": 0,
    "bos_token": 1,
    "eos_token": 2
}